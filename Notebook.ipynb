{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.python.client import device_lib\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "#from skimage import exposure\n",
    "#from skimage.color import rgb2gray\n",
    "import platform\n",
    "import sys\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy data: (70, 160, 320, 3)\n",
      "70 images of 160 x 320 RGB\n"
     ]
    }
   ],
   "source": [
    "driving = \"driving_01\"\n",
    "\n",
    "input_files = []\n",
    "\n",
    "# read CSV file with steering angle\n",
    "csvdata = pd.read_csv(\"./data/\" + driving + \".csv\", header=None)\n",
    "nlabels = csvdata.shape[0]\n",
    "\n",
    "# original shape\n",
    "owidth = 320\n",
    "oheight = 160\n",
    "\n",
    "# crop\n",
    "stripetop = 60\n",
    "stripebot = 20\n",
    "\n",
    "# \n",
    "# Images are in a Zip file, easier to upload to github\n",
    "# \n",
    "with ZipFile(\"./data/\" + driving + \".zip\") as f:\n",
    "    image_list = f.namelist()\n",
    "    \n",
    "    # image size is given as matrix, row X columns\n",
    "    shape = (nlabels, oheight, owidth,  3)\n",
    "    \n",
    "    # CROP\n",
    "    # cropping before training saves memory\n",
    "    # but leaving the crop to the model allows better autonomous mode on the track\n",
    "    \n",
    "    # loop through csv lines\n",
    "    #X_data = np.zeros((3*nlabels, oheight, owidth,  3), np.float)\n",
    "    #y_data = np.zeros(3*nlabels, np.float)\n",
    "    #for row in csvdata.iterrows():\n",
    "    #    pass\n",
    "    \n",
    "    X_data = np.zeros(shape, np.float)\n",
    "    y_data = np.zeros(nlabels, np.float)\n",
    "    for k in range(1, len(image_list)):\n",
    "        image = image_list[k]\n",
    "        if image[11:17] == 'center':\n",
    "            #ir = mpimg.imread(f.open(image), format='jpeg')\n",
    "            #print(ir.shape, image)\n",
    "            X_data[k-1, :, :, :] = mpimg.imread(f.open(image), format='jpeg')\n",
    "\n",
    "\n",
    "y_data = y_data + csvdata.iloc[:, 3]\n",
    "print(\"Numpy data:\", X_data.shape)\n",
    "print(X_data.shape[0], \"images of\", X_data.shape[1], \"x\", X_data.shape[2], \"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 160, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could use sample data (provided) as test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testdata = pd.read_csv(\"./sample-data/driving.csv\", header=None)\n",
    "#y_test = y_test + testdata.iloc[:, 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed model has 5 convolutional layers and 4 fully connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Lambda, MaxPooling2D\n",
    "from keras.layers import Cropping2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import __version__ as keras_version\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# CROP images\n",
    "model.add(Cropping2D(cropping=((stripetop, stripebot), (0,0)), input_shape=(oheight, owidth, 3)))\n",
    "\n",
    "# normalization and mean centering\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5))\n",
    "\n",
    "# layer 1 - convolutional\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_data.shape[1], X_data.shape[2], X_data.shape[3])))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# layer 2\n",
    "#model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "\n",
    "# layer 3\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# layer 4\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# layer 5\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "\n",
    "# layer 6\n",
    "#model.add(Dense(1))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# layer 7\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "# layer 8\n",
    "#model.add(Dense(100, activation='relu'))\n",
    "#model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# layer 9\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_2 (Cropping2D)    (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 78, 318, 16)       448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 39, 159, 16)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 99216)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 99217     \n",
      "=================================================================\n",
      "Total params: 99,665\n",
      "Trainable params: 99,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 1s - loss: 0.3396 - val_loss: 1.3101\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s - loss: 1.6806 - val_loss: 0.4166\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s - loss: 0.8365 - val_loss: 2.0098\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s - loss: 2.2515 - val_loss: 0.0673\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s - loss: 0.2474 - val_loss: 0.4733\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s - loss: 0.5500 - val_loss: 0.1695\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s - loss: 0.2727 - val_loss: 0.4668\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s - loss: 0.6853 - val_loss: 0.3986\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "ee = 1e-6\n",
    "cb_earlystop = EarlyStopping(min_delta=ee, patience=3, verbose=1)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(X_train, y_train, \n",
    "          batch_size=32, \n",
    "          epochs=10, \n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          callbacks=[cb_earlystop], \n",
    "          verbose=1)\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-15f73ec0e8c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_model('model.h5')\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
